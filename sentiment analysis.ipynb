{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ea4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31ca6e66",
   "metadata": {},
   "source": [
    "### dataset - Kaggle\n",
    "## link: https://www.kaggle.com/datasets/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54654f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40964153",
   "metadata": {},
   "outputs": [],
   "source": [
    "column =[\"Target\",\"id\",\"time\",\"flag\",\"user\",\"tweet\"]\n",
    "originaldata = pd.read_csv(\"twittersentiment.csv\",encoding='latin')\n",
    "originaldata.columns=column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6633cf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target          id                          time      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                               tweet  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366eb95b",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3bae0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                                              tweet\n",
       "0       0  is upset that he can't update his Facebook by ...\n",
       "1       0  @Kenichan I dived many times for the ball. Man...\n",
       "2       0    my whole body feels itchy and like its on fire \n",
       "3       0  @nationwideclass no, it's not behaving at all....\n",
       "4       0                      @Kwesidei not the whole crew "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the unwanted columns : id , time, flag,user\n",
    "data = originaldata\n",
    "data = data.drop([\"id\",\"time\",\"flag\",\"user\"],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de7d2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target    0\n",
       "tweet     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing for nan or null values - since our data depends on only the tweet column, is its nan or null, it doesnt provide any info\n",
    "#hence we are removing\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22346db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target    0\n",
       "tweet     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb92801b",
   "metadata": {},
   "source": [
    "## Analyze and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a7012b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    799999\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from the website:\n",
    "# 4- positive\n",
    "# 2- neutral\n",
    "# 0- negative\n",
    "data[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1504eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph\n",
    "import seaborn as sns\n",
    "#from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162b83c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the distribution for dataset.\n",
    "ax = data.groupby('Target').count().plot(kind='bar', title='Distribution of data',legend=False)\n",
    "ax.set_xticklabels(['Negative','Positive'], rotation=0)\n",
    "# Storing data in lists.\n",
    "text, sentiment = list(data['tweet']), list(data['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76a379cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                                              tweet\n",
       "0       0  is upset that he can't update his Facebook by ...\n",
       "1       0  @Kenichan I dived many times for the ball. Man...\n",
       "2       0    my whole body feels itchy and like its on fire \n",
       "3       0  @nationwideclass no, it's not behaving at all....\n",
       "4       0                      @Kwesidei not the whole crew "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnegative = data.loc[data['Target']== 0]\n",
    "dfnegative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a6145ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpositive = data.loc[data['Target']== 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94efa89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\kavya\\anaconda3\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e67e9a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0c51138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7cda627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599994    just woke up. having no school is the best fee...\n",
       "1599995    thewdb.com - very cool to hear old walt interv...\n",
       "1599996    are you ready for your mojo makeover? ask me f...\n",
       "1599997    happy 38th birthday to my boo of alll time!!! ...\n",
       "1599998    happy #charitytuesday @thenspcc @sparkscharity...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet']=data['tweet'].str.lower()\n",
    "data['tweet'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "478f413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a1f25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a634e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    upset can't update facebook texting it... migh...\n",
       "1    @kenichan dived many times ball. managed save ...\n",
       "2                     whole body feels itchy like fire\n",
       "3    @nationwideclass no, it's not behaving all. i'...\n",
       "4                             @kwesidei not whole crew\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwordlist)\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "data['tweet'] = data['tweet'].apply(lambda text: cleaning_stopwords(text))\n",
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f359f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    upset cant update facebook texting it might cr...\n",
       "1    kenichan dived many times ball managed save 50...\n",
       "2                     whole body feels itchy like fire\n",
       "3    nationwideclass no its not behaving all im mad...\n",
       "4                              kwesidei not whole crew\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "data['tweet']= data['tweet'].apply(lambda x: cleaning_punctuations(x))\n",
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bcc5ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    upset cant update facebook texting it might cr...\n",
       "1    kenichan dived many times ball managed save 50...\n",
       "2                     whole body feels itchy like fire\n",
       "3    nationwideclass no its not behaving all im mad...\n",
       "4                              kwesidei not whole crew\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "data['tweet'] = data['tweet'].apply(lambda x: cleaning_repeating_char(x))\n",
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "546ebd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    upset cant update facebook texting it might cr...\n",
       "1    kenichan dived many times ball managed save 50...\n",
       "2                     whole body feels itchy like fire\n",
       "3    nationwideclass no its not behaving all im mad...\n",
       "4                              kwesidei not whole crew\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "data['tweet'] = data['tweet'].apply(lambda x: cleaning_URLs(x))\n",
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "565bcabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    upset cant update facebook texting it might cr...\n",
       "1    kenichan dived many times ball managed save  r...\n",
       "2                     whole body feels itchy like fire\n",
       "3    nationwideclass no its not behaving all im mad...\n",
       "4                              kwesidei not whole crew\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "data['tweet'] = data['tweet'].apply(lambda x: cleaning_numbers(x))\n",
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "022fa119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           []\n",
       "1           []\n",
       "2          [w]\n",
       "3          [w]\n",
       "4    [w, w, w]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'w+')\n",
    "data['tweet'] = data['tweet'].apply(tokenizer.tokenize)\n",
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddc986b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           []\n",
       "1           []\n",
       "2          [w]\n",
       "3          [w]\n",
       "4    [w, w, w]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data\n",
    "data['tweet']= data['tweet'].apply(lambda x: stemming_on_text(x))\n",
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "202eef23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           []\n",
       "1           []\n",
       "2          [w]\n",
       "3          [w]\n",
       "4    [w, w, w]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = nltk.WordNetLemmatizer()\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lm.lemmatize(word) for word in data]\n",
    "    return data\n",
    "data['tweet'] = data['tweet'].apply(lambda x: lemmatizer_on_text(x))\n",
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcb0b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.tweet\n",
    "y=data.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbc931ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cded8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9be42012",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23228/2022486912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1342\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    855\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    856\u001b[0m         \"\"\"\n\u001b[1;32m--> 857\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ec010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9bb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a347d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2030251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#breaking sentences down to small tokens\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "#The fit_on_texts() method creates an association between the words and the assigned numbers. \n",
    "#This association is stored in the form of a dictionary in the tokenizer.word_index attribute.\n",
    "tokenizer.fit_on_texts(data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19795bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    is upset that he can't update his Facebook by ...\n",
       "1    @Kenichan I dived many times for the ball. Man...\n",
       "2      my whole body feels itchy and like its on fire \n",
       "3    @nationwideclass no, it's not behaving at all....\n",
       "4                        @Kwesidei not the whole crew \n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "699bdaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the  with the numbers\n",
    "encoded_docs = tokenizer.texts_to_sequences(data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "700fccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making each sentence with equal length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "326b75ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   40  273 1170]\n",
      " [   0    0    0 ...   37   31   12]\n",
      " [   0    0    0 ...   71   13 1169]\n",
      " ...\n",
      " [   0    0    0 ...   14   11 2107]\n",
      " [   0    0    0 ...  501   12   50]\n",
      " [   0    0    0 ...    0    0  119]]\n"
     ]
    }
   ],
   "source": [
    "print(padded_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4bc45a",
   "metadata": {},
   "source": [
    "## Spliting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37453fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequence,data[\"Target\"], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad3369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa5d9c1",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "##### 1. Linear Regression\n",
    "##### 2. Support Vector Machines\n",
    "##### 3. RNN derivatives LSTM and GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b17e08ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kavya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5222575757575758\n"
     ]
    }
   ],
   "source": [
    "#linear regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9099f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - linear\n",
    "from sklearn import svm\n",
    "lsvm = svm.SVC()\n",
    "lsvm.fit(X_.train, y_train)\n",
    "prediction = lsvm.predict(X_test)\n",
    "print(accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b61859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "sgd = Pipeline([\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639279d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7d16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cda873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3595203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kavya\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kavya\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "398f24e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9477ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
